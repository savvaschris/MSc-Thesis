\chapter{Conclusion and future work}
\label{chap:conclusion-and-future-work}

\section{Future work}
\label{sec:future-work}

One direction most researchers are turning in order to lower the running times, is the usage of general purpose GPU programming. Our current implementation runs the order of seconds and can easily run in real-time with a GPGPU implementation. Also the use of texture features in a more efficient and intelligent way may help with the problem of similar colours in foreground and background. Another consideration specific for our application is the use of the new Kinect that has been already launched for home entertainment purposes and is expected to be released for developers at the end of 2014. Reports from developers that participated in the Developer Preview Program express that the depth will be produced by an indirect time of flight method \cite{kinectscomparison} and thus be more accurate. Also the colour stream will in 1920x1080 resolution and the depth 512x424. The differences are illustrated in Appendix A.
Finally, a recent insight was to use illumination information as prior data. Various light detection algorithms that could be used exist in the literature. If illumination information for each object in the scene could be isolated, then we could separate regions based on the light that reaches them. To be more specific, by following the idea in \cite{flash}, the foreground will be illuminated differently than the background or than other objects in the scene.

\section{Conclusion}
\label{sec:conclusion}

The overall goal of matting research is to develop an intelligent, efficient, user friendly method that can extract high quality alpha mattes, in any scenario. There are of course a lot of challenges and a lot of problems that have not been effectively solved yet. The main problem is the quality of the extracted mattes that is not yet comparable to that of blue screen matting or triangulation. Also the efficiency of certain algorithms is an issue, to be specific, algorithms that have good results still require many seconds to run for low resolution images, and photos that are used in the industry today are in the order of mega pixels. In \cite{mattingtutorial} the presenters showed matting results with state of the art methods on images taken from a smartphone, a tablet and an SLR camera and the matting algorithms required minutes to run and the results contained artifacts that were not acceptable.   
In reality, extracting a quality matte still requires a lot of human effort using image editing software, and for video sequences that do not use green screen, rotoscoping has to be used, where Bezier curves are hand drawn around foreground objects every few frames and other processing techniques are used to get the final travelling matte, which again requires a lot of human effort \cite{visualeffects}.
\par
In our approach the main problem is the quality for images with difficult backgrounds i.e. backgrounds that have similar colours with the foreground. Also for highly transparent images we havenâ€™t added a refinement method for the smoothness of the alpha matte. Another issue are the erroneous regions in the trimap that is incorrectly generated with the Kinect sensor due to the low quality depth-map that is produced. 
\par
Possible solutions to the matting problem in general, is usage of more advanced machine learning techniques without the consideration of time constrains until a satisfactory result is generated and then from that point, research should be done to optimize the formulation and also design of application specific hardware for optimal running times, similarly to the way the computer graphics rendering pipeline was implemented on graphics cards. 
To conclude, natural image matting has a variety of applications and could be very helpful for graphics designers, video editors and film producers. Automating the process will also branch out new augmented reality and virtual reality applications. There will also be contributions in solving the segmentation problem in computer vision.
